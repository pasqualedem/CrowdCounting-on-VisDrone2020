from easydict import EasyDict
import time

__C = EasyDict()
cfg = __C

__C.SEED = 3035  # random seed

# System settings
__C.TRAIN_BATCH_SIZE = 4
__C.VAL_BATCH_SIZE = 6
__C.N_WORKERS = 4

__C.PRE_TRAINED = None

# path settings
__C.EXP_PATH = './exp'
__C.DATASET = 'VisDrone'
__C.NET = 'MobileCountx0_5'
__C.DETAILS = '_1080x1920'

# learning rate settings
__C.LR = 1e-4  # learning rate
__C.LR_DECAY = 0.995  # decay rate
__C.LR_DECAY_START = -1  # when training epoch is more than it, the learning rate will be begin to decay
__C.NUM_EPOCH_LR_DECAY = 1  # decay frequency
__C.MAX_EPOCH = 500

__C.PATIENCE = 15
__C.EARLY_STOP_DELTA = 1e-2

# print
__C.PRINT_FREQ = 10

now = time.strftime("%m-%d_%H-%M", time.localtime())
__C.EXP_NAME = now \
               + '_' + __C.DATASET \
               + '_' + __C.NET \
               + '_' + str(__C.LR) \
               + '_' + __C.DETAILS
__C.DEVICE = 'cuda'  # cpu or cuda

# ------------------------------VAL------------------------
__C.VAL_SIZE = 0.2
__C.VAL_DENSE_START = 1
__C.VAL_FREQ = 10  # Before __C.VAL_DENSE_START epoches, the freq is set as __C.VAL_FREQ




===============+++++++++++++++===============

all_ep_1_mae_68.9_mse_89.0
    [mae 68.86 mse 89.03], [val loss 3.6022]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_3_mae_36.6_mse_47.2
    [mae 36.59 mse 47.22], [val loss 3.0457]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_4_mae_44.2_mse_56.2
    [mae 44.23 mse 56.22], [val loss 3.0790]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_5_mae_60.0_mse_79.7
    [mae 60.00 mse 79.66], [val loss 2.9512]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_6_mae_53.4_mse_62.3
    [mae 53.41 mse 62.31], [val loss 2.8831]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_7_mae_40.7_mse_48.2
    [mae 40.66 mse 48.23], [val loss 2.7263]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_8_mae_14.3_mse_18.1
    [mae 14.27 mse 18.14], [val loss 2.6830]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_9_mae_21.0_mse_24.7
    [mae 21.01 mse 24.72], [val loss 2.6390]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_10_mae_64.2_mse_76.9
    [mae 64.23 mse 76.92], [val loss 2.7363]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_11_mae_11.2_mse_14.0
    [mae 11.16 mse 13.97], [val loss 2.5548]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_12_mae_22.5_mse_30.8
    [mae 22.46 mse 30.76], [val loss 2.5446]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_13_mae_15.3_mse_19.0
    [mae 15.30 mse 18.99], [val loss 2.4960]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_14_mae_17.7_mse_22.4
    [mae 17.73 mse 22.37], [val loss 2.4708]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_15_mae_33.4_mse_39.8
    [mae 33.37 mse 39.84], [val loss 2.5199]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_16_mae_36.4_mse_45.7
    [mae 36.36 mse 45.71], [val loss 2.4640]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_17_mae_26.3_mse_34.6
    [mae 26.35 mse 34.57], [val loss 2.4432]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_18_mae_52.3_mse_59.2
    [mae 52.30 mse 59.15], [val loss 2.5349]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_19_mae_25.0_mse_34.7
    [mae 25.03 mse 34.70], [val loss 2.3857]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_20_mae_61.0_mse_75.6
    [mae 61.02 mse 75.57], [val loss 2.5104]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_21_mae_14.3_mse_19.0
    [mae 14.31 mse 19.05], [val loss 2.3599]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_22_mae_26.2_mse_35.5
    [mae 26.20 mse 35.54], [val loss 2.3497]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_23_mae_27.2_mse_37.9
    [mae 27.20 mse 37.90], [val loss 2.3309]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_24_mae_51.7_mse_59.3
    [mae 51.66 mse 59.29], [val loss 2.3978]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_25_mae_31.6_mse_45.8
    [mae 31.62 mse 45.82], [val loss 2.3348]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_26_mae_40.3_mse_55.6
    [mae 40.35 mse 55.60], [val loss 2.3589]
===============+++++++++++++++===============

