from easydict import EasyDict
import time

__C = EasyDict()
cfg = __C

__C.SEED = 3035  # random seed

# System settings
__C.TRAIN_BATCH_SIZE = 2
__C.VAL_BATCH_SIZE = 6
__C.N_WORKERS = 4

__C.PRE_TRAINED = None

# path settings
__C.EXP_PATH = './exp'
__C.DATASET = 'VisDrone'
__C.NET = 'MobileCountx0_75'
__C.DETAILS = '_1080x1920_NVS'

# learning optimizer settings
__C.LR = 1e-4  # learning rate
__C.W_DECAY = 1e-4  # weight decay
__C.LR_DECAY = 0.995  # decay rate
__C.LR_DECAY_START = 0  # when training epoch is more than it, the learning rate will be begin to decay
__C.NUM_EPOCH_LR_DECAY = 1  # decay frequency
__C.MAX_EPOCH = 500

__C.OPTIM_ADAM = ('Adam',
                  {
                      'lr': __C.LR,
                      'weight_decay': __C.W_DECAY,
                  })
__C.OPTIM_SGD = ('SGD',
                  {
                      'lr': __C.LR,
                      'weight_decay': __C.W_DECAY,
                      'momentum': 0.95
                  })

__C.OPTIM = __C.OPTIM_ADAM  # Chosen optimizer

__C.PATIENCE = 15
__C.EARLY_STOP_DELTA = 1e-2

# print
__C.PRINT_FREQ = 10

now = time.strftime("%m-%d_%H-%M", time.localtime())
__C.EXP_NAME = now \
               + '_' + __C.DATASET \
               + '_' + __C.NET \
               + '_' + str(__C.LR) \
               + '_' + __C.DETAILS
__C.DEVICE = 'cuda'  # cpu or cuda

# ------------------------------VAL------------------------
__C.VAL_SIZE = 0.2
__C.VAL_DENSE_START = 1
__C.VAL_FREQ = 10  # Before __C.VAL_DENSE_START epoches, the freq is set as __C.VAL_FREQ




===============+++++++++++++++===============

all_ep_1_mae_75.9_mse_110.9
    [mae 75.85 mse 110.93], [val loss 3.5939]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_3_mae_37.3_mse_46.6
    [mae 37.33 mse 46.61], [val loss 3.1602]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_4_mae_48.0_mse_62.3
    [mae 48.02 mse 62.34], [val loss 3.1674]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_5_mae_59.0_mse_75.2
    [mae 58.97 mse 75.23], [val loss 3.1325]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_6_mae_38.7_mse_51.4
    [mae 38.73 mse 51.41], [val loss 3.0527]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_7_mae_52.0_mse_67.8
    [mae 52.01 mse 67.76], [val loss 3.1157]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_8_mae_58.5_mse_72.9
    [mae 58.51 mse 72.92], [val loss 3.0274]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_9_mae_56.4_mse_78.8
    [mae 56.43 mse 78.80], [val loss 3.0643]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_10_mae_36.1_mse_42.8
    [mae 36.14 mse 42.78], [val loss 2.9634]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_11_mae_37.7_mse_48.4
    [mae 37.70 mse 48.39], [val loss 2.9798]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_12_mae_45.4_mse_53.6
    [mae 45.42 mse 53.56], [val loss 2.9512]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_13_mae_49.8_mse_56.7
    [mae 49.83 mse 56.67], [val loss 3.0053]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_14_mae_47.2_mse_54.2
    [mae 47.24 mse 54.19], [val loss 2.9523]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_15_mae_62.4_mse_80.3
    [mae 62.37 mse 80.28], [val loss 3.0380]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_16_mae_62.0_mse_83.6
    [mae 62.04 mse 83.56], [val loss 3.0042]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_17_mae_34.0_mse_41.6
    [mae 33.97 mse 41.65], [val loss 2.8809]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_18_mae_31.5_mse_37.4
    [mae 31.49 mse 37.41], [val loss 2.8909]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_19_mae_51.2_mse_67.8
    [mae 51.22 mse 67.77], [val loss 2.9795]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_20_mae_50.7_mse_61.3
    [mae 50.71 mse 61.29], [val loss 2.9544]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_21_mae_41.4_mse_46.9
    [mae 41.37 mse 46.87], [val loss 2.9039]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_22_mae_53.7_mse_70.0
    [mae 53.67 mse 69.99], [val loss 2.9765]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_23_mae_70.9_mse_104.1
    [mae 70.93 mse 104.11], [val loss 3.1140]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_24_mae_37.8_mse_52.1
    [mae 37.84 mse 52.06], [val loss 2.9015]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_25_mae_44.2_mse_55.2
    [mae 44.24 mse 55.21], [val loss 2.9780]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_26_mae_37.6_mse_44.1
    [mae 37.63 mse 44.09], [val loss 2.8893]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_27_mae_34.8_mse_41.9
    [mae 34.78 mse 41.89], [val loss 2.8793]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_28_mae_41.0_mse_49.7
    [mae 40.98 mse 49.68], [val loss 2.9196]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_29_mae_45.1_mse_56.9
    [mae 45.07 mse 56.88], [val loss 2.9251]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_30_mae_51.1_mse_66.9
    [mae 51.08 mse 66.87], [val loss 2.9868]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_31_mae_45.6_mse_53.2
    [mae 45.64 mse 53.23], [val loss 2.9604]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_32_mae_40.8_mse_48.7
    [mae 40.75 mse 48.70], [val loss 2.9196]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_33_mae_46.6_mse_56.6
    [mae 46.58 mse 56.57], [val loss 2.9589]
===============+++++++++++++++===============

