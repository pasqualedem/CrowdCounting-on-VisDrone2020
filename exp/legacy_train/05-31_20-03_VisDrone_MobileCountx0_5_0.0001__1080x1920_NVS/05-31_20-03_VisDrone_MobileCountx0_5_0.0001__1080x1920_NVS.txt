from easydict import EasyDict
import time

__C = EasyDict()
cfg = __C

__C.SEED = 3035  # random seed

# System settings
__C.TRAIN_BATCH_SIZE = 4
__C.VAL_BATCH_SIZE = 6
__C.N_WORKERS = 4

__C.PRE_TRAINED = None

# path settings
__C.EXP_PATH = './exp'
__C.DATASET = 'VisDrone'
__C.NET = 'MobileCountx0_5'
__C.DETAILS = '_1080x1920_NVS'

# learning optimizer settings
__C.LR = 1e-4  # learning rate
__C.W_DECAY = 1e-4  # weight decay
__C.LR_DECAY = 0.995  # decay rate
__C.LR_DECAY_START = 0  # when training epoch is more than it, the learning rate will be begin to decay
__C.NUM_EPOCH_LR_DECAY = 1  # decay frequency
__C.MAX_EPOCH = 500

__C.OPTIM_ADAM = ('Adam',
                  {
                      'lr': __C.LR,
                      'weight_decay': __C.W_DECAY,
                  })
__C.OPTIM_SGD = ('SGD',
                  {
                      'lr': __C.LR,
                      'weight_decay': __C.W_DECAY,
                      'momentum': 0.95
                  })

__C.OPTIM = __C.OPTIM_ADAM  # Chosen optimizer

__C.PATIENCE = 15
__C.EARLY_STOP_DELTA = 1e-2

# print
__C.PRINT_FREQ = 10

now = time.strftime("%m-%d_%H-%M", time.localtime())
__C.EXP_NAME = now \
               + '_' + __C.DATASET \
               + '_' + __C.NET \
               + '_' + str(__C.LR) \
               + '_' + __C.DETAILS
__C.DEVICE = 'cuda'  # cpu or cuda

# ------------------------------VAL------------------------
__C.VAL_SIZE = 0.2
__C.VAL_DENSE_START = 1
__C.VAL_FREQ = 10  # Before __C.VAL_DENSE_START epoches, the freq is set as __C.VAL_FREQ




===============+++++++++++++++===============

all_ep_1_mae_113.4_mse_163.5
    [mae 113.36 mse 163.47], [val loss 3.9275]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_3_mae_47.7_mse_57.0
    [mae 47.73 mse 56.98], [val loss 3.4041]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_4_mae_53.8_mse_72.4
    [mae 53.77 mse 72.42], [val loss 3.3763]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_5_mae_41.5_mse_51.3
    [mae 41.50 mse 51.29], [val loss 3.2896]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_6_mae_30.0_mse_38.3
    [mae 30.04 mse 38.35], [val loss 3.2058]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_7_mae_47.4_mse_61.0
    [mae 47.36 mse 60.98], [val loss 3.2707]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_8_mae_39.5_mse_49.8
    [mae 39.47 mse 49.83], [val loss 3.2182]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_9_mae_74.1_mse_100.0
    [mae 74.14 mse 100.01], [val loss 3.3260]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_10_mae_27.4_mse_34.9
    [mae 27.44 mse 34.90], [val loss 3.0938]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_11_mae_38.7_mse_47.8
    [mae 38.72 mse 47.76], [val loss 3.1541]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_12_mae_32.2_mse_39.2
    [mae 32.22 mse 39.19], [val loss 3.1409]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_13_mae_74.5_mse_92.2
    [mae 74.45 mse 92.24], [val loss 3.2881]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_14_mae_36.0_mse_43.3
    [mae 36.03 mse 43.27], [val loss 3.0858]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_15_mae_57.1_mse_75.0
    [mae 57.12 mse 75.04], [val loss 3.1732]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_16_mae_32.7_mse_40.7
    [mae 32.72 mse 40.69], [val loss 3.0764]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_17_mae_46.3_mse_61.3
    [mae 46.33 mse 61.31], [val loss 3.0984]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_18_mae_39.4_mse_50.0
    [mae 39.42 mse 49.95], [val loss 3.0945]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_19_mae_40.1_mse_45.2
    [mae 40.12 mse 45.16], [val loss 3.0631]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_20_mae_48.7_mse_67.9
    [mae 48.75 mse 67.93], [val loss 3.1331]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_21_mae_35.9_mse_44.8
    [mae 35.89 mse 44.85], [val loss 3.0357]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_22_mae_45.4_mse_61.8
    [mae 45.36 mse 61.78], [val loss 3.1124]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_23_mae_38.0_mse_43.5
    [mae 37.96 mse 43.50], [val loss 3.0371]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_24_mae_53.9_mse_73.4
    [mae 53.87 mse 73.40], [val loss 3.1525]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_25_mae_38.9_mse_49.6
    [mae 38.91 mse 49.61], [val loss 3.0875]
===============+++++++++++++++===============

