from easydict import EasyDict
import time

__C = EasyDict()
cfg = __C

__C.SEED = 3035  # random seed

# System settings
__C.TRAIN_BATCH_SIZE = 2
__C.VAL_BATCH_SIZE = 6
__C.N_WORKERS = 4

__C.PRE_TRAINED = None

# path settings
__C.EXP_PATH = './exp'
__C.DATASET = 'VisDrone'
__C.NET = 'MobileCount'
__C.DETAILS = '_1080x1920_SGD'

# learning optimizer settings
__C.LR = 1e-4  # learning rate
__C.W_DECAY = 1e-4  # weight decay
__C.LR_DECAY = 0.995  # decay rate
__C.LR_DECAY_START = 0  # when training epoch is more than it, the learning rate will be begin to decay
__C.NUM_EPOCH_LR_DECAY = 1  # decay frequency
__C.MAX_EPOCH = 500

__C.OPTIM_ADAM = ('Adam',
                  {
                      'lr': __C.LR,
                      'weight_decay': __C.W_DECAY,
                  })
__C.OPTIM_SGD = ('SGD',
                  {
                      'lr': __C.LR,
                      'weight_decay': __C.W_DECAY,
                      'momentum': 0.95
                  })

__C.OPTIM = __C.OPTIM_SGD  # Chosen optimizer

__C.PATIENCE = 15
__C.EARLY_STOP_DELTA = 1e-2

# print
__C.PRINT_FREQ = 10

now = time.strftime("%m-%d_%H-%M", time.localtime())
__C.EXP_NAME = now \
               + '_' + __C.DATASET \
               + '_' + __C.NET \
               + '_' + str(__C.LR) \
               + '_' + __C.DETAILS
__C.DEVICE = 'cuda'  # cpu or cuda

# ------------------------------VAL------------------------
__C.VAL_SIZE = 0.2
__C.VAL_DENSE_START = 1
__C.VAL_FREQ = 10  # Before __C.VAL_DENSE_START epoches, the freq is set as __C.VAL_FREQ




===============+++++++++++++++===============

all_ep_1_mae_69.0_mse_90.4
    [mae 68.99 mse 90.41], [val loss 4.5762]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_3_mae_52.5_mse_69.0
    [mae 52.50 mse 68.96], [val loss 3.9502]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_4_mae_74.1_mse_96.9
    [mae 74.12 mse 96.93], [val loss 3.8416]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_5_mae_62.6_mse_85.3
    [mae 62.57 mse 85.28], [val loss 3.8071]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_6_mae_75.4_mse_90.3
    [mae 75.41 mse 90.33], [val loss 3.7106]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_7_mae_73.4_mse_103.2
    [mae 73.39 mse 103.25], [val loss 3.6778]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_8_mae_117.8_mse_170.3
    [mae 117.82 mse 170.32], [val loss 3.7599]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_9_mae_51.5_mse_69.4
    [mae 51.53 mse 69.42], [val loss 3.6113]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_10_mae_83.4_mse_102.1
    [mae 83.37 mse 102.13], [val loss 3.7117]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_11_mae_73.4_mse_111.7
    [mae 73.40 mse 111.75], [val loss 3.5583]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_12_mae_65.8_mse_95.1
    [mae 65.76 mse 95.06], [val loss 3.5257]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_13_mae_53.2_mse_70.2
    [mae 53.24 mse 70.24], [val loss 3.4748]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_14_mae_61.6_mse_90.8
    [mae 61.56 mse 90.80], [val loss 3.5722]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_15_mae_93.2_mse_112.0
    [mae 93.23 mse 111.97], [val loss 3.7224]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_16_mae_52.2_mse_65.9
    [mae 52.17 mse 65.88], [val loss 3.5090]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_17_mae_41.7_mse_56.0
    [mae 41.71 mse 56.00], [val loss 3.4507]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_18_mae_106.7_mse_162.8
    [mae 106.72 mse 162.81], [val loss 3.6174]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_19_mae_50.7_mse_62.0
    [mae 50.73 mse 61.98], [val loss 3.4407]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_20_mae_52.8_mse_69.7
    [mae 52.77 mse 69.73], [val loss 3.4216]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_21_mae_77.8_mse_96.6
    [mae 77.78 mse 96.62], [val loss 3.6126]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_22_mae_94.4_mse_114.1
    [mae 94.40 mse 114.07], [val loss 3.6980]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_23_mae_50.3_mse_61.5
    [mae 50.28 mse 61.48], [val loss 3.4200]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_24_mae_50.2_mse_63.5
    [mae 50.20 mse 63.45], [val loss 3.4302]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_25_mae_52.3_mse_62.7
    [mae 52.31 mse 62.68], [val loss 3.3875]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_26_mae_46.1_mse_58.2
    [mae 46.06 mse 58.22], [val loss 3.4063]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_27_mae_53.4_mse_65.1
    [mae 53.37 mse 65.12], [val loss 3.3789]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_28_mae_41.7_mse_56.2
    [mae 41.74 mse 56.19], [val loss 3.3584]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_29_mae_54.7_mse_80.4
    [mae 54.67 mse 80.40], [val loss 3.3854]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_30_mae_54.2_mse_70.9
    [mae 54.20 mse 70.94], [val loss 3.4317]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_31_mae_62.5_mse_90.6
    [mae 62.45 mse 90.59], [val loss 3.3848]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_32_mae_46.2_mse_56.9
    [mae 46.25 mse 56.88], [val loss 3.3442]
===============+++++++++++++++===============

