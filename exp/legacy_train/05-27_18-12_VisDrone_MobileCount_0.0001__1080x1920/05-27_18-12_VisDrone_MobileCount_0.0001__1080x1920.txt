from easydict import EasyDict
import time

__C = EasyDict()
cfg = __C

__C.SEED = 3035  # random seed

# System settings
__C.TRAIN_BATCH_SIZE = 2
__C.VAL_BATCH_SIZE = 6
__C.N_WORKERS = 4

__C.PRE_TRAINED = None

# path settings
__C.EXP_PATH = './exp'
__C.DATASET = 'VisDrone'
__C.NET = 'MobileCount'
__C.DETAILS = '_1080x1920'

# learning rate settings
__C.LR = 1e-4  # learning rate
__C.LR_DECAY = 0.995  # decay rate
__C.LR_DECAY_START = -1  # when training epoch is more than it, the learning rate will be begin to decay
__C.NUM_EPOCH_LR_DECAY = 1  # decay frequency
__C.MAX_EPOCH = 500
__C.INIT_EPOCH = 0

__C.PATIENCE = 15
__C.EARLY_STOP_DELTA = 1e-2

# print
__C.PRINT_FREQ = 10

now = time.strftime("%m-%d_%H-%M", time.localtime())
__C.EXP_NAME = now \
               + '_' + __C.DATASET \
               + '_' + __C.NET \
               + '_' + str(__C.LR) \
               + '_' + __C.DETAILS
__C.DEVICE = 'cuda'  # cpu or cuda

# ------------------------------VAL------------------------
__C.VAL_SIZE = 0.2
__C.VAL_DENSE_START = 1
__C.VAL_FREQ = 10  # Before __C.VAL_DENSE_START epoches, the freq is set as __C.VAL_FREQ




===============+++++++++++++++===============

all_ep_1_mae_32.4_mse_42.7
    [mae 32.36 mse 42.68], [val loss 3.2425]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_3_mae_82.8_mse_97.8
    [mae 82.84 mse 97.80], [val loss 3.1899]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_4_mae_53.7_mse_78.3
    [mae 53.75 mse 78.31], [val loss 2.8017]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_5_mae_30.6_mse_44.2
    [mae 30.60 mse 44.23], [val loss 2.7068]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_6_mae_16.9_mse_22.9
    [mae 16.87 mse 22.91], [val loss 2.5843]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_7_mae_37.7_mse_55.3
    [mae 37.71 mse 55.27], [val loss 2.5627]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_8_mae_19.7_mse_25.0
    [mae 19.69 mse 25.03], [val loss 2.4670]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_9_mae_22.3_mse_28.8
    [mae 22.31 mse 28.82], [val loss 2.5098]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_10_mae_37.9_mse_50.8
    [mae 37.88 mse 50.83], [val loss 2.4473]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_11_mae_23.0_mse_31.9
    [mae 22.97 mse 31.87], [val loss 2.3503]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_12_mae_23.1_mse_33.1
    [mae 23.14 mse 33.05], [val loss 2.3338]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_13_mae_52.8_mse_68.1
    [mae 52.78 mse 68.10], [val loss 2.4100]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_14_mae_15.1_mse_21.0
    [mae 15.05 mse 21.02], [val loss 2.2527]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_15_mae_26.1_mse_34.4
    [mae 26.11 mse 34.35], [val loss 2.3129]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_16_mae_9.8_mse_12.8
    [mae 9.76 mse 12.85], [val loss 2.2196]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_17_mae_33.7_mse_45.7
    [mae 33.69 mse 45.70], [val loss 2.2348]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_18_mae_55.3_mse_81.1
    [mae 55.32 mse 81.09], [val loss 2.3379]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_19_mae_16.7_mse_22.6
    [mae 16.67 mse 22.61], [val loss 2.1685]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_20_mae_17.3_mse_23.2
    [mae 17.27 mse 23.25], [val loss 2.1741]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_21_mae_16.2_mse_25.0
    [mae 16.21 mse 24.97], [val loss 2.1396]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_22_mae_14.4_mse_19.5
    [mae 14.43 mse 19.47], [val loss 2.1357]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_23_mae_26.7_mse_40.4
    [mae 26.71 mse 40.39], [val loss 2.1244]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_24_mae_24.5_mse_38.2
    [mae 24.50 mse 38.17], [val loss 2.1124]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_25_mae_22.6_mse_33.5
    [mae 22.60 mse 33.54], [val loss 2.1220]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_26_mae_24.1_mse_35.2
    [mae 24.09 mse 35.18], [val loss 2.1037]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_27_mae_26.2_mse_37.8
    [mae 26.17 mse 37.80], [val loss 2.0899]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_28_mae_12.2_mse_17.1
    [mae 12.18 mse 17.06], [val loss 2.0537]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_29_mae_16.4_mse_23.6
    [mae 16.36 mse 23.56], [val loss 2.0574]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_30_mae_16.0_mse_23.4
    [mae 16.01 mse 23.35], [val loss 2.0271]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_31_mae_10.7_mse_15.6
    [mae 10.68 mse 15.56], [val loss 2.0370]
===============+++++++++++++++===============

