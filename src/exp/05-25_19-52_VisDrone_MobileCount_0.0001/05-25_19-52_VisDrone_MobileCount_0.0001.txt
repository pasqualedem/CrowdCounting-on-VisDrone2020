from easydict import EasyDict
import time

__C = EasyDict()
cfg = __C

__C.TRAIN_BATCH_SIZE = 2
__C.VAL_BATCH_SIZE = 8
__C.N_WORKERS = 4

__C.PRE_TRAINED = None
__C.EXP_PATH = './exp'
__C.DATASET = 'VisDrone'
__C.NET = 'MobileCount'

# learning rate settings
__C.LR = 1e-4  # learning rate
__C.LR_DECAY = 0.995  # decay rate
__C.LR_DECAY_START = -1  # when training epoch is more than it, the learning rate will be begin to decay
__C.NUM_EPOCH_LR_DECAY = 1  # decay frequency
__C.MAX_EPOCH = 500
__C.INIT_EPOCH = 0

# print
__C.PRINT_FREQ = 10

now = time.strftime("%m-%d_%H-%M", time.localtime())
__C.EXP_NAME = now \
               + '_' + __C.DATASET \
               + '_' + __C.NET \
               + '_' + str(__C.LR)
__C.DEVICE = 'cuda'  # cpu or cuda

# ------------------------------VAL------------------------
__C.VAL_SIZE = 0.2
__C.VAL_DENSE_START = 1
__C.VAL_FREQ = 10  # Before __C.VAL_DENSE_START epoches, the freq is set as __C.VAL_FREQ




===============+++++++++++++++===============

all_ep_1_mae_42.7_mse_55.0
    [mae 42.70 mse 54.98], [val loss 3.1028]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_4_mae_19.5_mse_26.7
    [mae 19.50 mse 26.72], [val loss 2.4767]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_9_mae_10.8_mse_14.2
    [mae 10.78 mse 14.24], [val loss 2.2077]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_15_mae_10.2_mse_13.1
    [mae 10.24 mse 13.11], [val loss 2.0440]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_29_mae_9.7_mse_13.2
    [mae 9.72 mse 13.24], [val loss 1.8717]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_38_mae_9.1_mse_12.1
    [mae 9.09 mse 12.11], [val loss 1.8362]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_39_mae_7.7_mse_10.7
    [mae 7.71 mse 10.66], [val loss 1.8152]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_49_mae_7.3_mse_10.0
    [mae 7.26 mse 9.99], [val loss 1.7917]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_58_mae_7.4_mse_9.9
    [mae 7.43 mse 9.92], [val loss 1.7398]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_64_mae_6.9_mse_9.9
    [mae 6.94 mse 9.88], [val loss 1.7231]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_75_mae_7.3_mse_9.7
    [mae 7.29 mse 9.71], [val loss 1.7116]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_76_mae_6.9_mse_9.4
    [mae 6.93 mse 9.40], [val loss 1.7071]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_90_mae_6.2_mse_8.4
    [mae 6.23 mse 8.41], [val loss 1.6809]
===============+++++++++++++++===============

