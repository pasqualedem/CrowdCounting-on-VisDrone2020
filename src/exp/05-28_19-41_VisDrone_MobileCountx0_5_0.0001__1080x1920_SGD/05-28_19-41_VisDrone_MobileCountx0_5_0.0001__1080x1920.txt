from easydict import EasyDict
import time

__C = EasyDict()
cfg = __C

__C.SEED = 3035  # random seed

# System settings
__C.TRAIN_BATCH_SIZE = 4
__C.VAL_BATCH_SIZE = 6
__C.N_WORKERS = 4

__C.PRE_TRAINED = None

# path settings
__C.EXP_PATH = './exp'
__C.DATASET = 'VisDrone'
__C.NET = 'MobileCountx0_5'
__C.DETAILS = '_1080x1920'

# learning rate settings
__C.LR = 1e-4  # learning rate
__C.LR_DECAY = 0.995  # decay rate
__C.LR_DECAY_START = -1  # when training epoch is more than it, the learning rate will be begin to decay
__C.NUM_EPOCH_LR_DECAY = 1  # decay frequency
__C.MAX_EPOCH = 500

__C.PATIENCE = 15
__C.EARLY_STOP_DELTA = 1e-2

# print
__C.PRINT_FREQ = 10

now = time.strftime("%m-%d_%H-%M", time.localtime())
__C.EXP_NAME = now \
               + '_' + __C.DATASET \
               + '_' + __C.NET \
               + '_' + str(__C.LR) \
               + '_' + __C.DETAILS
__C.DEVICE = 'cuda'  # cpu or cuda

# ------------------------------VAL------------------------
__C.VAL_SIZE = 0.2
__C.VAL_DENSE_START = 1
__C.VAL_FREQ = 10  # Before __C.VAL_DENSE_START epoches, the freq is set as __C.VAL_FREQ




===============+++++++++++++++===============

all_ep_1_mae_68.8_mse_90.9
    [mae 68.81 mse 90.89], [val loss 4.5798]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_3_mae_69.1_mse_90.8
    [mae 69.15 mse 90.82], [val loss 4.5798]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_4_mae_69.0_mse_90.8
    [mae 69.00 mse 90.84], [val loss 4.5798]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_5_mae_69.1_mse_90.8
    [mae 69.15 mse 90.81], [val loss 4.5797]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_6_mae_69.3_mse_90.8
    [mae 69.30 mse 90.80], [val loss 4.5797]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_7_mae_68.9_mse_90.8
    [mae 68.87 mse 90.84], [val loss 4.5796]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_8_mae_69.2_mse_90.8
    [mae 69.16 mse 90.76], [val loss 4.5794]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_9_mae_69.3_mse_90.7
    [mae 69.34 mse 90.70], [val loss 4.5789]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_10_mae_69.0_mse_90.4
    [mae 69.00 mse 90.39], [val loss 4.5768]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_11_mae_68.5_mse_88.1
    [mae 68.48 mse 88.10], [val loss 4.5544]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_12_mae_92.1_mse_118.9
    [mae 92.14 mse 118.89], [val loss 4.3042]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_13_mae_74.6_mse_91.7
    [mae 74.63 mse 91.71], [val loss 4.2211]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_14_mae_109.7_mse_143.2
    [mae 109.70 mse 143.17], [val loss 4.1133]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_15_mae_110.5_mse_129.2
    [mae 110.45 mse 129.18], [val loss 4.0448]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_16_mae_125.8_mse_145.2
    [mae 125.84 mse 145.17], [val loss 4.0736]
===============+++++++++++++++===============

